{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assign4DAI.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSM_jJop_MMt",
        "colab_type": "text"
      },
      "source": [
        "<h1>Assignment4</h1>\n",
        "\n",
        "Priyanka Raavi\n",
        "\n",
        "Student ID: 200393260\n",
        "\n",
        "Email: priyankaravi03@gmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrQZNm7z_SPK",
        "colab_type": "text"
      },
      "source": [
        "<h4>Problem Statement</h4>\n",
        "Our problem Statement is, How can I survive on mushrooms by identifying whether it is poisonous or edible, which means which factors should be considered to identify whether a mushroom is edible or poisonous. \n",
        "\n",
        "Based on the problem statement, we have to classify because we have only to separate, which are poisonous or edible and also, our data set is large and has the labeled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsjYjTf9_ZWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e34b8078-501c-4866-e58f-50b4ff8ae76a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPGe9G5F_bEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7c11c79-2423-4ad0-ab3e-5fa1e4135582"
      },
      "source": [
        "cd /content/gdrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0tueupj_hz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78c9ae4e-4e6e-4ccb-c62c-bc5e786f8002"
      },
      "source": [
        "cd My\\ Drive"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtLjqCFe_jcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mlt\n",
        "import seaborn as sns\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6jFENVc_l6S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%precision 3\n",
        "plt.style.use('ggplot')\n",
        "sns.set_style('white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXsYzDix_p3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mushrooms = pd.read_csv('mushrooms.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzzUTmiQ_tFP",
        "colab_type": "text"
      },
      "source": [
        "<h3>Part A: Determine a proper model</h3>\n",
        "\n",
        "To define our problem statement, we need a perfect model. To know which model suits best with the data, I would like to perform multiple machine learning algorithm to do classification on the data and see which algorithm gives good accuracy will select that model to continue our problem statement.\n",
        "\n",
        "The machine learning algorithms are of three types[1]:\n",
        "\n",
        "    1.Supervised Learning\n",
        "    2.Unsupervised Learning\n",
        "    3.Reinforcement Learning\n",
        "\n",
        "\n",
        "<h4>1. Supervised Learning:</h4>\n",
        "\n",
        "   This algorithm has a target variable(dependent) and labeled data(independent). We will split the data into train data and test data. Using this train data, we will use functions that generate the desired outputs, which provides excellent accuracy. This process will continue until we get the desired accuracy on the training data.\n",
        "\n",
        "<h4>2. Unsupervised Learning:</h4>\n",
        "  \n",
        "   This algorithm doesn't have any separation of target and predicate variables. In this algorithm, we will draw inferences from the input data without any labeled data. It is mostly a clustering analysis.\n",
        "   \n",
        "<h4>Reinforcement Learning</h4>\n",
        "\n",
        "This algorithm is more used to make particular business decisions. In this algorithm, we will get the results based on past experiences. This algorithm is more exposed to the environment and learns itself by trail and error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylt64JJG_zYF",
        "colab_type": "text"
      },
      "source": [
        "I'm going to apply supervised machine learning algorithms on our data set to test which algorithm is best suited for the data. I have taken the supervised learning algorithms because, our data set is more of labeled data, and based on our problem statement, we have a target variable(class). So, In my opinion, supervised learning algorithms are best suited. Here, I would like to perform five supervised learning algorithms:\n",
        "1. Logistic Regression\n",
        "2. Support Vector Machines\n",
        "3. K-nearest Neighbours(K-NN)\n",
        "4. Naive-Bayes Classifier\n",
        "5. Decision Tree Classifier\n",
        "\n",
        "I will explain each algorithm in detail while performing it.\n",
        "\n",
        "Before going to perform the algorithms, we have to preprocess the data because all the variables in the data set are categorical. So, Let's preprocess the data.\n",
        "\n",
        "<h4> Data Preprocessing</h4>\n",
        "\n",
        "I'm converting the categorical variables(23) into dummy variables up to 95 variables and then reduce the shape using PCA(Principal Component Analysis) with two variables.\n",
        "\n",
        "First, Let's split the data into predictors and responses.\n",
        "\n",
        "Predicators are the independent variables(all the variables except class) whereas, the response is the class variable(target variable).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EbKdW90_6ws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "3814deea-4867-43a1-b5e5-bcf6ba5aeb21"
      },
      "source": [
        "pred=mushrooms.drop('class',axis=1) #Predictors\n",
        "resp=mushrooms['class'] #Response\n",
        "pred.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stalk-shape</th>\n",
              "      <th>stalk-root</th>\n",
              "      <th>stalk-surface-above-ring</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>n</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>k</td>\n",
              "      <td>e</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>y</td>\n",
              "      <td>t</td>\n",
              "      <td>a</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>e</td>\n",
              "      <td>c</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>b</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>l</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>b</td>\n",
              "      <td>n</td>\n",
              "      <td>e</td>\n",
              "      <td>c</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x</td>\n",
              "      <td>y</td>\n",
              "      <td>w</td>\n",
              "      <td>t</td>\n",
              "      <td>p</td>\n",
              "      <td>f</td>\n",
              "      <td>c</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>e</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>p</td>\n",
              "      <td>k</td>\n",
              "      <td>s</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x</td>\n",
              "      <td>s</td>\n",
              "      <td>g</td>\n",
              "      <td>f</td>\n",
              "      <td>n</td>\n",
              "      <td>f</td>\n",
              "      <td>w</td>\n",
              "      <td>b</td>\n",
              "      <td>k</td>\n",
              "      <td>t</td>\n",
              "      <td>e</td>\n",
              "      <td>s</td>\n",
              "      <td>s</td>\n",
              "      <td>w</td>\n",
              "      <td>w</td>\n",
              "      <td>p</td>\n",
              "      <td>w</td>\n",
              "      <td>o</td>\n",
              "      <td>e</td>\n",
              "      <td>n</td>\n",
              "      <td>a</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  cap-shape cap-surface cap-color  ... spore-print-color population habitat\n",
              "0         x           s         n  ...                 k          s       u\n",
              "1         x           s         y  ...                 n          n       g\n",
              "2         b           s         w  ...                 n          n       m\n",
              "3         x           y         w  ...                 k          s       u\n",
              "4         x           s         g  ...                 n          a       g\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qopIuzZ__UD",
        "colab_type": "text"
      },
      "source": [
        "Converting or Encoding the Categorical data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh_DCHDZ_7Nu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "Encoder_pred = LabelEncoder() \n",
        "for col in pred.columns:\n",
        "    pred[col] = Encoder_pred.fit_transform(pred[col])\n",
        "Encoder_resp=LabelEncoder()\n",
        "resp = Encoder_pred.fit_transform(resp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBb1O5SN_9HD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "49ac7115-f30c-44e9-bd08-5c190d54ed8c"
      },
      "source": [
        "pred.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-shape</th>\n",
              "      <th>cap-surface</th>\n",
              "      <th>cap-color</th>\n",
              "      <th>bruises</th>\n",
              "      <th>odor</th>\n",
              "      <th>gill-attachment</th>\n",
              "      <th>gill-spacing</th>\n",
              "      <th>gill-size</th>\n",
              "      <th>gill-color</th>\n",
              "      <th>stalk-shape</th>\n",
              "      <th>stalk-root</th>\n",
              "      <th>stalk-surface-above-ring</th>\n",
              "      <th>stalk-surface-below-ring</th>\n",
              "      <th>stalk-color-above-ring</th>\n",
              "      <th>stalk-color-below-ring</th>\n",
              "      <th>veil-type</th>\n",
              "      <th>veil-color</th>\n",
              "      <th>ring-number</th>\n",
              "      <th>ring-type</th>\n",
              "      <th>spore-print-color</th>\n",
              "      <th>population</th>\n",
              "      <th>habitat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   cap-shape  cap-surface  cap-color  ...  spore-print-color  population  habitat\n",
              "0          5            2          4  ...                  2           3        5\n",
              "1          5            2          9  ...                  3           2        1\n",
              "2          0            2          8  ...                  3           2        3\n",
              "3          5            3          8  ...                  2           3        5\n",
              "4          5            2          3  ...                  3           0        1\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHDhPUi6ACAK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c4883c4-9d97-445e-8092-fbe9f92e1ae4"
      },
      "source": [
        "resp   # here 1 means poisonous, 0 means edible"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b-dib-HAFt4",
        "colab_type": "text"
      },
      "source": [
        "Now, Let's create the dummy variables using the pandas library in such a way that, based on the number of unique values. It creates no. of variables based on no. of unique values in each variable. For example, cap-shape has 5 values, so it created 5 variables. 0 and 1 represent true or false values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Js1lRBADdg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "4819ab9d-0d7f-49bc-a940-e08b8de4f18b"
      },
      "source": [
        "pred=pd.get_dummies(pred,columns=pred.columns,drop_first=True)\n",
        "pred.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-shape_1</th>\n",
              "      <th>cap-shape_2</th>\n",
              "      <th>cap-shape_3</th>\n",
              "      <th>cap-shape_4</th>\n",
              "      <th>cap-shape_5</th>\n",
              "      <th>cap-surface_1</th>\n",
              "      <th>cap-surface_2</th>\n",
              "      <th>cap-surface_3</th>\n",
              "      <th>cap-color_1</th>\n",
              "      <th>cap-color_2</th>\n",
              "      <th>cap-color_3</th>\n",
              "      <th>cap-color_4</th>\n",
              "      <th>cap-color_5</th>\n",
              "      <th>cap-color_6</th>\n",
              "      <th>cap-color_7</th>\n",
              "      <th>cap-color_8</th>\n",
              "      <th>cap-color_9</th>\n",
              "      <th>bruises_1</th>\n",
              "      <th>odor_1</th>\n",
              "      <th>odor_2</th>\n",
              "      <th>odor_3</th>\n",
              "      <th>odor_4</th>\n",
              "      <th>odor_5</th>\n",
              "      <th>odor_6</th>\n",
              "      <th>odor_7</th>\n",
              "      <th>odor_8</th>\n",
              "      <th>gill-attachment_1</th>\n",
              "      <th>gill-spacing_1</th>\n",
              "      <th>gill-size_1</th>\n",
              "      <th>gill-color_1</th>\n",
              "      <th>gill-color_2</th>\n",
              "      <th>gill-color_3</th>\n",
              "      <th>gill-color_4</th>\n",
              "      <th>gill-color_5</th>\n",
              "      <th>gill-color_6</th>\n",
              "      <th>gill-color_7</th>\n",
              "      <th>gill-color_8</th>\n",
              "      <th>gill-color_9</th>\n",
              "      <th>gill-color_10</th>\n",
              "      <th>gill-color_11</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-color-above-ring_5</th>\n",
              "      <th>stalk-color-above-ring_6</th>\n",
              "      <th>stalk-color-above-ring_7</th>\n",
              "      <th>stalk-color-above-ring_8</th>\n",
              "      <th>stalk-color-below-ring_1</th>\n",
              "      <th>stalk-color-below-ring_2</th>\n",
              "      <th>stalk-color-below-ring_3</th>\n",
              "      <th>stalk-color-below-ring_4</th>\n",
              "      <th>stalk-color-below-ring_5</th>\n",
              "      <th>stalk-color-below-ring_6</th>\n",
              "      <th>stalk-color-below-ring_7</th>\n",
              "      <th>stalk-color-below-ring_8</th>\n",
              "      <th>veil-color_1</th>\n",
              "      <th>veil-color_2</th>\n",
              "      <th>veil-color_3</th>\n",
              "      <th>ring-number_1</th>\n",
              "      <th>ring-number_2</th>\n",
              "      <th>ring-type_1</th>\n",
              "      <th>ring-type_2</th>\n",
              "      <th>ring-type_3</th>\n",
              "      <th>ring-type_4</th>\n",
              "      <th>spore-print-color_1</th>\n",
              "      <th>spore-print-color_2</th>\n",
              "      <th>spore-print-color_3</th>\n",
              "      <th>spore-print-color_4</th>\n",
              "      <th>spore-print-color_5</th>\n",
              "      <th>spore-print-color_6</th>\n",
              "      <th>spore-print-color_7</th>\n",
              "      <th>spore-print-color_8</th>\n",
              "      <th>population_1</th>\n",
              "      <th>population_2</th>\n",
              "      <th>population_3</th>\n",
              "      <th>population_4</th>\n",
              "      <th>population_5</th>\n",
              "      <th>habitat_1</th>\n",
              "      <th>habitat_2</th>\n",
              "      <th>habitat_3</th>\n",
              "      <th>habitat_4</th>\n",
              "      <th>habitat_5</th>\n",
              "      <th>habitat_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 95 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   cap-shape_1  cap-shape_2  cap-shape_3  ...  habitat_4  habitat_5  habitat_6\n",
              "0            0            0            0  ...          0          1          0\n",
              "1            0            0            0  ...          0          0          0\n",
              "2            0            0            0  ...          0          0          0\n",
              "3            0            0            0  ...          0          1          0\n",
              "4            0            0            0  ...          0          0          0\n",
              "\n",
              "[5 rows x 95 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWoRdL5rALYh",
        "colab_type": "text"
      },
      "source": [
        "Now, Lets split the dataset as train set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Ibr0U8AI2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "pred_train, pred_test, resp_train, resp_test = train_test_split(pred, resp, test_size=0.1, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj0p79eeAQYH",
        "colab_type": "text"
      },
      "source": [
        "We are scaling the pred data using StandardScaler library[2]. This library assumes that, In each variable, the data is distributed normally, and then it scales the distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha08cfSmAN2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "pred_train = sc.fit_transform(pred_train)\n",
        "pred_test = sc.transform(pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "551m3ilAAXCf",
        "colab_type": "text"
      },
      "source": [
        "After scaling the data, we will use PCA to reduce the variables with no. of components 2. Here we are using PCA because PCA could \"transform the set of observations of possibly correlated variables to set of values of linearly uncorrelated variables\"[3]. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVRp8JqWATGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "pred_train = pca.fit_transform(pred_train)\n",
        "pred_test = pca.transform(pred_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdBMvdDbAc4k",
        "colab_type": "text"
      },
      "source": [
        "Let's see how the trained data set look like:\n",
        "\n",
        "Now, we will introduce each supervised learning algorithm we thought to test and see the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iQnK0_JAaCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "def print_score(classifier,X_train,y_train,X_test,y_test,train=True):\n",
        "    if train == True:\n",
        "        print(\"Training results:\\n\")\n",
        "        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_train,classifier.predict(X_train))))\n",
        "        \n",
        "    elif train == False:\n",
        "        print(\"Test results:\\n\")\n",
        "        print('Accuracy Score: {0:.4f}\\n'.format(accuracy_score(y_test,classifier.predict(X_test))))\n",
        "        res = cross_val_score(classifier, X_train, y_train, cv=10, n_jobs=-1, scoring='accuracy')\n",
        "        print('Average Accuracy:\\t{0:.4f}\\n'.format(res.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9akHnHyAkqf",
        "colab_type": "text"
      },
      "source": [
        "<h4>Testing the Models</h4>\n",
        "\n",
        "1. Logistic Regression:\n",
        "\n",
        "      This algorithm is used when the target variable is categorical[4] or when the target variable is binary. Same as all regression algorithms, this algorithm is also used for prediction analysis. It uses a black-box function called softmax, which describes the relationship between the target variable with the other independent variables[5]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsjAZbktAloe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0c59fecc-26bd-4d0c-b190-267facf97dea"
      },
      "source": [
        "#let's fit the logistic regression to the train set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "classifier.fit(pred_train,resp_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjUETVUPAnEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "70fd05f6-4df0-4ab1-bfe8-5e7accc6b9f4"
      },
      "source": [
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=True)\n",
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training results:\n",
            "\n",
            "Accuracy Score: 0.9056\n",
            "\n",
            "Test results:\n",
            "\n",
            "Accuracy Score: 0.9028\n",
            "\n",
            "Average Accuracy:\t0.9056\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDDb-I6KA0T3",
        "colab_type": "text"
      },
      "source": [
        "2. Support Vector Machine(SVM):\n",
        "\n",
        "     This kind of algorithm is used to decide by creating a line or a hyperplane that separates the data into different classes and make sure the difference between the classes is as vast as possible[6]. It can solve linear and non-linear problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71j_xCKVAoPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "be31eee4-6959-4683-c970-b58dea492f40"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel='rbf',random_state=42)\n",
        "\n",
        "classifier.fit(pred_train,resp_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='rbf', max_iter=-1, probability=False, random_state=42,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buIs4oZoA4XM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "272567b9-68a3-43f6-960b-5b6d2ce76f0d"
      },
      "source": [
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=True)\n",
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=False)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training results:\n",
            "\n",
            "Accuracy Score: 0.9279\n",
            "\n",
            "Test results:\n",
            "\n",
            "Accuracy Score: 0.9262\n",
            "\n",
            "Average Accuracy:\t0.9265\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfi4lJfTA8cy",
        "colab_type": "text"
      },
      "source": [
        "3.K-Nearest Neighbour(K-NN):\n",
        "\n",
        "       This algorithm works based on minimum distance from the query instance to the training samples to determine the k- nearest neighbors. After we gather k nearest neighbors, we take a simple majority of these k-nearest neighbors to be the prediction of the query instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNySFho_A5DA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "03d0b198-e7b0-468e-8d54-ba7dc6a1b4f0"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "\n",
        "classifier = KNN()\n",
        "classifier.fit(pred_train,resp_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luZdvQTvA-9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "a91df207-f7ed-4dba-b857-9100f57575e2"
      },
      "source": [
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=True)\n",
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training results:\n",
            "\n",
            "Accuracy Score: 0.9427\n",
            "\n",
            "Test results:\n",
            "\n",
            "Accuracy Score: 0.9274\n",
            "\n",
            "Average Accuracy:\t0.9291\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjhSEjMPBC76",
        "colab_type": "text"
      },
      "source": [
        "4.Naive-Bayes Classifier:\n",
        "\n",
        "   It is a dominant and straightforward algorithm based on Bayes theorem. It is the best-suited algorithm for textual data analysis classification with millions of records. This algorithm makes predictions on the membership probabilities of each class[7]. The class, which has the highest chance, is mostly used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgS1is5mBAKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e134e38f-0342-4cc2-cece-5f6094a03c98"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB as NB\n",
        "\n",
        "classifier = NB()\n",
        "classifier.fit(pred_train,resp_train)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stlwLaQfBFUr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "87285012-a5a0-4b15-c42f-9ddc6708bd4d"
      },
      "source": [
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=True)\n",
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training results:\n",
            "\n",
            "Accuracy Score: 0.8980\n",
            "\n",
            "Test results:\n",
            "\n",
            "Accuracy Score: 0.8967\n",
            "\n",
            "Average Accuracy:\t0.8977\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5O5zIBSBKp4",
        "colab_type": "text"
      },
      "source": [
        "5. Decision Tree:\n",
        "\n",
        "This algorithm is used to create a training set which can be used to predict the target variables by learning decision rules from the train data set.This algorithm is used for both classification and regression as well. In this algorithm, the data is been split, prune and then does the tree selection based on entropy[8]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0DEjDxBGx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "519768f8-a8a0-4860-ff78-26aea6faac43"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier as DT\n",
        "\n",
        "classifier = DT(criterion='entropy',random_state=42)\n",
        "classifier.fit(pred_train,resp_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
              "                       max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort=False,\n",
              "                       random_state=42, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJLUfhArBNLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "987cb74e-4875-4c1d-9ef9-3061ee9e3730"
      },
      "source": [
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=True)\n",
        "print_score(classifier,pred_train,resp_train,pred_test,resp_test,train=False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training results:\n",
            "\n",
            "Accuracy Score: 1.0000\n",
            "\n",
            "Test results:\n",
            "\n",
            "Accuracy Score: 0.9065\n",
            "\n",
            "Average Accuracy:\t0.9004\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5HKtSKjBRtc",
        "colab_type": "text"
      },
      "source": [
        "Based on the results of testing all the supervised learning models, I got to know that, K-NN models is best suited for this data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQPu31jhBUQ8",
        "colab_type": "text"
      },
      "source": [
        "<h3> Part B&C: Apply the Algorithm & Visualization</h3>\n",
        "\n",
        "K-Nearest Neighbor(K-NN):\n",
        "\n",
        "K-NN is the most used and simple supervised learning algorithm. It works based on minimum distance from the query instance to the training samples to determine the k- nearest neighbors rather than making assumptions on the data, the prediction is retrieved from the data itself. It doesn't need much training phase because it uses the train data during the testing phase. This algorithm is based on feature similarity. The pseudo code of the algorithm as below:\n",
        "\n",
        "1. Load the data\n",
        "2. Based on the no. of neighbors we set, we will initialize K.\n",
        "3. For every example in the data,\n",
        "\n",
        "       i. we will calculate the distance between the data of the current example and the question.\n",
        "       ii. And then, we will add that distance to the index of the instance to an ordered data.\n",
        "4. Sort them in ascending order.\n",
        "5. Pick the K entries which come first from that sorted collection.\n",
        "6. Get the labels of the first k entries.\n",
        "7.Return the mode of the K labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQx8AkkUBgc7",
        "colab_type": "text"
      },
      "source": [
        "The pre-processing of data to use this model had already done. so, we will just use that data and create a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGFc7zOFBOpa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "8e394850-19d0-4e19-dde7-89f7361e6ae6"
      },
      "source": [
        "pred.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cap-shape_1</th>\n",
              "      <th>cap-shape_2</th>\n",
              "      <th>cap-shape_3</th>\n",
              "      <th>cap-shape_4</th>\n",
              "      <th>cap-shape_5</th>\n",
              "      <th>cap-surface_1</th>\n",
              "      <th>cap-surface_2</th>\n",
              "      <th>cap-surface_3</th>\n",
              "      <th>cap-color_1</th>\n",
              "      <th>cap-color_2</th>\n",
              "      <th>cap-color_3</th>\n",
              "      <th>cap-color_4</th>\n",
              "      <th>cap-color_5</th>\n",
              "      <th>cap-color_6</th>\n",
              "      <th>cap-color_7</th>\n",
              "      <th>cap-color_8</th>\n",
              "      <th>cap-color_9</th>\n",
              "      <th>bruises_1</th>\n",
              "      <th>odor_1</th>\n",
              "      <th>odor_2</th>\n",
              "      <th>odor_3</th>\n",
              "      <th>odor_4</th>\n",
              "      <th>odor_5</th>\n",
              "      <th>odor_6</th>\n",
              "      <th>odor_7</th>\n",
              "      <th>odor_8</th>\n",
              "      <th>gill-attachment_1</th>\n",
              "      <th>gill-spacing_1</th>\n",
              "      <th>gill-size_1</th>\n",
              "      <th>gill-color_1</th>\n",
              "      <th>gill-color_2</th>\n",
              "      <th>gill-color_3</th>\n",
              "      <th>gill-color_4</th>\n",
              "      <th>gill-color_5</th>\n",
              "      <th>gill-color_6</th>\n",
              "      <th>gill-color_7</th>\n",
              "      <th>gill-color_8</th>\n",
              "      <th>gill-color_9</th>\n",
              "      <th>gill-color_10</th>\n",
              "      <th>gill-color_11</th>\n",
              "      <th>...</th>\n",
              "      <th>stalk-color-above-ring_5</th>\n",
              "      <th>stalk-color-above-ring_6</th>\n",
              "      <th>stalk-color-above-ring_7</th>\n",
              "      <th>stalk-color-above-ring_8</th>\n",
              "      <th>stalk-color-below-ring_1</th>\n",
              "      <th>stalk-color-below-ring_2</th>\n",
              "      <th>stalk-color-below-ring_3</th>\n",
              "      <th>stalk-color-below-ring_4</th>\n",
              "      <th>stalk-color-below-ring_5</th>\n",
              "      <th>stalk-color-below-ring_6</th>\n",
              "      <th>stalk-color-below-ring_7</th>\n",
              "      <th>stalk-color-below-ring_8</th>\n",
              "      <th>veil-color_1</th>\n",
              "      <th>veil-color_2</th>\n",
              "      <th>veil-color_3</th>\n",
              "      <th>ring-number_1</th>\n",
              "      <th>ring-number_2</th>\n",
              "      <th>ring-type_1</th>\n",
              "      <th>ring-type_2</th>\n",
              "      <th>ring-type_3</th>\n",
              "      <th>ring-type_4</th>\n",
              "      <th>spore-print-color_1</th>\n",
              "      <th>spore-print-color_2</th>\n",
              "      <th>spore-print-color_3</th>\n",
              "      <th>spore-print-color_4</th>\n",
              "      <th>spore-print-color_5</th>\n",
              "      <th>spore-print-color_6</th>\n",
              "      <th>spore-print-color_7</th>\n",
              "      <th>spore-print-color_8</th>\n",
              "      <th>population_1</th>\n",
              "      <th>population_2</th>\n",
              "      <th>population_3</th>\n",
              "      <th>population_4</th>\n",
              "      <th>population_5</th>\n",
              "      <th>habitat_1</th>\n",
              "      <th>habitat_2</th>\n",
              "      <th>habitat_3</th>\n",
              "      <th>habitat_4</th>\n",
              "      <th>habitat_5</th>\n",
              "      <th>habitat_6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 95 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   cap-shape_1  cap-shape_2  cap-shape_3  ...  habitat_4  habitat_5  habitat_6\n",
              "0            0            0            0  ...          0          1          0\n",
              "1            0            0            0  ...          0          0          0\n",
              "2            0            0            0  ...          0          0          0\n",
              "3            0            0            0  ...          0          1          0\n",
              "4            0            0            0  ...          0          0          0\n",
              "\n",
              "[5 rows x 95 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLYUTXDWBihL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00c54d70-0736-455e-a99c-a6f711508ee3"
      },
      "source": [
        "resp"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qo0ngk9BmL2",
        "colab_type": "text"
      },
      "source": [
        "To initialize K, What would be the optimal K value?. Let figure out that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQGL2Y2TBkIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# creating odd list of K for KNN\n",
        "myList = list(range(1,200))\n",
        "\n",
        "# empty list that will hold cv scores\n",
        "cv_scores = []\n",
        "\n",
        "# perform 10-fold cross validation\n",
        "for k in myList[::2]:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    scores = cross_val_score(knn, pred_train, resp_train, cv=10, scoring='accuracy')\n",
        "    cv_scores.append(scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wz1y0lPBo9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "a9d18605-2313-4980-e1cb-fe672998a992"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "# changing to misclassification error\n",
        "MSE = [1 - x for x in cv_scores]\n",
        "\n",
        "# determining best k\n",
        "optimal_k = myList[::2][MSE.index(min(MSE))]\n",
        "print (\"The optimal number of neighbors is %d\" % optimal_k)\n",
        "\n",
        "# plot misclassification error vs k\n",
        "plt.plot(myList[::2], MSE)\n",
        "plt.xlabel('Number of Neighbors K')\n",
        "plt.ylabel('Misclassification Error')\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal number of neighbors is 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAENCAYAAADHbvgVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI0lFCCFEtZGkIoQQotr8Py0q2n4xeDhzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx4baEqXCJ-p",
        "colab_type": "text"
      },
      "source": [
        "Now, lets continue to implement our algorithm to our data set by specifying the no. of neighbors to 15 as it is the optimal no. of neighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyza_BCzCGaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10b4c85c-ee86-4c50-9c22-e4cc81434b5c"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier =  KNeighborsClassifier(n_neighbors=15,p=2, metric='minkowski')\n",
        "classifier.fit(pred_train,resp_train)\n",
        "resp_pred = classifier.predict(pred_test)\n",
        "accuracy_score(resp_test,resp_pred)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kih_OjW5CSU8",
        "colab_type": "text"
      },
      "source": [
        "Let's see What factors or features to be considered for surviving on mushrooms?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTMfWx4qCMt9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1705
        },
        "outputId": "3d55e5ee-afca-4fdd-a701-ff4c00b777fd"
      },
      "source": [
        "n_features = pred.shape[1]\n",
        "clf = KNeighborsClassifier()\n",
        "feature_score = []\n",
        "# calculating the score to each feature.\n",
        "for i in range(n_features):\n",
        "    pred_feature= np.reshape(pred.iloc[:,i:i+1],-1,1)\n",
        "    scores = cross_val_score(clf, pred_feature, resp)\n",
        "    feature_score.append(scores.mean())\n",
        "    print('%40s        %g' % (pred.columns[i], scores.mean()))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                             cap-shape_1        0.518464\n",
            "                             cap-shape_2        0.528923\n",
            "                             cap-shape_3        0.563777\n",
            "                             cap-shape_4        0.517971\n",
            "                             cap-shape_5        0.482275\n",
            "                           cap-surface_1        0.517971\n",
            "                           cap-surface_2        0.515533\n",
            "                           cap-surface_3        0.505908\n",
            "                             cap-color_1        0.517971\n",
            "                             cap-color_2        0.502831\n",
            "                             cap-color_3        0.494707\n",
            "                             cap-color_4        0.492747\n",
            "                             cap-color_5        0.514153\n",
            "                             cap-color_6        0.517971\n",
            "                             cap-color_7        0.517971\n",
            "                             cap-color_8        0.517971\n",
            "                             cap-color_9        0.551455\n",
            "                               bruises_1        0.517971\n",
            "                                  odor_1        0.541597\n",
            "                                  odor_2        0.783831\n",
            "                                  odor_3        0.517971\n",
            "                                  odor_4        0.517971\n",
            "                                  odor_5        0.584047\n",
            "                                  odor_6        0.517971\n",
            "                                  odor_7        0.588892\n",
            "                                  odor_8        0.588891\n",
            "                       gill-attachment_1        0.517971\n",
            "                          gill-spacing_1        0.517971\n",
            "                             gill-size_1        0.756319\n",
            "                            gill-color_1        0.517971\n",
            "                            gill-color_2        0.549471\n",
            "                            gill-color_3        0.559322\n",
            "                            gill-color_4        0.517971\n",
            "                            gill-color_5        0.517971\n",
            "                            gill-color_6        0.517971\n",
            "                            gill-color_7        0.474632\n",
            "                            gill-color_8        0.517971\n",
            "                            gill-color_9        0.517971\n",
            "                           gill-color_10        0.517971\n",
            "                           gill-color_11        0.517971\n",
            "                           stalk-shape_1        0.579987\n",
            "                            stalk-root_1        0.487568\n",
            "                            stalk-root_2        0.517971\n",
            "                            stalk-root_3        0.517971\n",
            "                            stalk-root_4        0.517971\n",
            "              stalk-surface-above-ring_1        0.774481\n",
            "              stalk-surface-above-ring_2        0.680548\n",
            "              stalk-surface-above-ring_3        0.517971\n",
            "              stalk-surface-below-ring_1        0.766109\n",
            "              stalk-surface-below-ring_2        0.570266\n",
            "              stalk-surface-below-ring_3        0.517971\n",
            "                stalk-color-above-ring_1        0.517971\n",
            "                stalk-color-above-ring_2        0.517971\n",
            "                stalk-color-above-ring_3        0.517971\n",
            "                stalk-color-above-ring_4        0.569164\n",
            "                stalk-color-above-ring_5        0.517971\n",
            "                stalk-color-above-ring_6        0.571783\n",
            "                stalk-color-above-ring_7        0.411044\n",
            "                stalk-color-above-ring_8        0.517971\n",
            "                stalk-color-below-ring_1        0.517971\n",
            "                stalk-color-below-ring_2        0.517971\n",
            "                stalk-color-below-ring_3        0.517971\n",
            "                stalk-color-below-ring_4        0.565223\n",
            "                stalk-color-below-ring_5        0.517971\n",
            "                stalk-color-below-ring_6        0.570921\n",
            "                stalk-color-below-ring_7        0.521172\n",
            "                stalk-color-below-ring_8        0.520926\n",
            "                            veil-color_1        0.517971\n",
            "                            veil-color_2        0.517971\n",
            "                            veil-color_3        0.517971\n",
            "                           ring-number_1        0.457388\n",
            "                           ring-number_2        0.452955\n",
            "                             ring-type_1        0.517971\n",
            "                             ring-type_2        0.677461\n",
            "                             ring-type_3        0.517971\n",
            "                             ring-type_4        0.563253\n",
            "                     spore-print-color_1        0.707\n",
            "                     spore-print-color_2        0.517971\n",
            "                     spore-print-color_3        0.517971\n",
            "                     spore-print-color_4        0.517971\n",
            "                     spore-print-color_5        0.526834\n",
            "                     spore-print-color_6        0.512188\n",
            "                     spore-print-color_7        0.609584\n",
            "                     spore-print-color_8        0.517971\n",
            "                            population_1        0.487926\n",
            "                            population_2        0.517971\n",
            "                            population_3        0.512432\n",
            "                            population_4        0.565731\n",
            "                            population_5        0.517971\n",
            "                               habitat_1        0.517971\n",
            "                               habitat_2        0.540382\n",
            "                               habitat_3        0.488071\n",
            "                               habitat_4        0.625318\n",
            "                               habitat_5        0.524247\n",
            "                               habitat_6        0.517971\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5v4tmlmCZPi",
        "colab_type": "text"
      },
      "source": [
        "These are the most considerable factors to identify which mushrooms are poisonous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xWIcG5mCU1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "144f12c4-047b-4142-b55c-78b89334988a"
      },
      "source": [
        "#Sorting the selected ordered collection in an ascending order\n",
        "imp_features = pd.Series(data = feature_score, index = pred.columns)\n",
        "imp_features.sort_values(ascending=True, inplace=True)\n",
        "imp_features[imp_features>0.7]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spore-print-color_1           0.707000\n",
              "gill-size_1                   0.756319\n",
              "stalk-surface-below-ring_1    0.766109\n",
              "stalk-surface-above-ring_1    0.774481\n",
              "odor_2                        0.783831\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnJYayFJCePX",
        "colab_type": "text"
      },
      "source": [
        "We got to know which top factors to identify whether a mushroom is poisonous or not. Let's see, to survive which mushrooms are edible and which are poisonous. To identify that, let's group the mushrooms that are edible and poisonous."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5LNLnIaCbsr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp_columns = imp_features[imp_features>0.7].index.values\n",
        "final_pr= pd.concat([pred,pd.DataFrame(resp,columns=['class'])], axis=1)\n",
        "grouped = final_pr.groupby('class')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Ak9G8WChhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "59d34b5b-df89-4bdf-8d72-9e97a6d0f454"
      },
      "source": [
        "# Edible group of mushrooms\n",
        "grouped.get_group(0)[imp_columns].sum()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spore-print-color_1            48\n",
              "gill-size_1                   288\n",
              "stalk-surface-below-ring_1    144\n",
              "stalk-surface-above-ring_1    144\n",
              "odor_2                          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLM1Lld0CjlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "600f0a50-15aa-4d03-cb69-135bc0f93433"
      },
      "source": [
        "# Poisonous group of mushrooms\n",
        "grouped.get_group(1)[imp_columns].sum()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spore-print-color_1           1584\n",
              "gill-size_1                   2224\n",
              "stalk-surface-below-ring_1    2160\n",
              "stalk-surface-above-ring_1    2228\n",
              "odor_2                        2160\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9FGWZwOC33R",
        "colab_type": "text"
      },
      "source": [
        "So, we got to know that, if the mushrooms indicate these factors, then those are poisonous. So, to survive on mushrooms, we should avoid them. The factors are: stalk surface above or below the ring is silky, the odor is foul, Gill Size is narrow, Spore prints are chocolatey in color."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G14wF5ebC6Oz",
        "colab_type": "text"
      },
      "source": [
        "<h3>Part D: Discussion</h3>\n",
        "\n",
        "K-NN is mostly used for the classification. As our data is categorical, K-NN is the best-suited algorithm. If we see the results of testing the 5 supervised learning algorithms, K-NN provided better accuracy rate among all. It is best suited for our data set and could predict the data. According to our data, it proved which mushrooms are poisonous or edible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyDiEaknC86v",
        "colab_type": "text"
      },
      "source": [
        "<h3>Part E: Summary</h3>\n",
        "\n",
        "TO conclude, The goal of the notebook is to know which is the best-suited algorithm to identify which mushroom is edible and which is poisonous. To achieve that, I have preprocessed the data as most of the data is categorical, I have created the dummy variables and performed PCA. Later, I have tested a few supervised learning algorithms and found the best algorithm(K-NN) that suited for the data. Later, I have implemented the K-NN algorithm by following the pseudo-code of K-NN and got the factors based which we could identify which mushroom is edible and which is poisonous.\n",
        "\n",
        "No other algorithm could able to predict with more accuracy rate than K-NN to this data set Whereas; Logistic regression would be the second-best option to use on this data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYsCemMnDCbQ",
        "colab_type": "text"
      },
      "source": [
        "<h3> References</h3>\n",
        "1. Analytics, B. and Codes), C. (2019). Essentials of Machine Learning Algorithms (with Python and R Codes). [online] Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2017/09/common-machine-learning-algorithms/ [Accessed 24 Aug. 2019].\n",
        "\n",
        "2.Keen, B. (2019). Feature Scaling with scikit-learn â€“ Ben Alex Keen. [online] Benalexkeen.com. Available at: http://benalexkeen.com/feature-scaling-with-scikit-learn/ [Accessed 24 Aug. 2019].\n",
        "\n",
        "3.wikipedia, w. (2019). Principal component analysis. [online] En.wikipedia.org. Available at: https://en.wikipedia.org/wiki/Principal_component_analysis [Accessed 24 Aug. 2019].\n",
        "\n",
        "4.Swaminathan, S. (2019). Logistic Regression â€” Detailed Overview. [online] Medium. Available at: https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc [Accessed 24 Aug. 2019].\n",
        "\n",
        "5.Solutions, S. (2019). What is Logistic Regression? - Statistics Solutions. [online] Statistics Solutions. Available at: https://www.statisticssolutions.com/what-is-logistic-regression/ [Accessed 24 Aug. 2019].\n",
        "\n",
        "6.Pupale, R. (2019). Support Vector Machines(SVM) â€” An Overview. [online] Medium. Available at: https://towardsdatascience.com/https-medium-com-pupalerushikesh-svm-f4b42800e989 [Accessed 24 Aug. 2019].\n",
        "\n",
        "7.Saxena, R. (2019). How the Naive Bayes Classifier works in Machine Learning. [online] Dataaspirant. Available at: https://dataaspirant.com/2017/02/06/naive-bayes-classifier-machine-learning/ [Accessed 24 Aug. 2019].\n",
        "\n",
        "8.Sehra, C. (2019). Decision Trees Explained Easily. [online] Medium. Available at: https://medium.com/@chiragsehra42/decision-trees-explained-easily-28f23241248 [Accessed 24 Aug. 2019].\n",
        "\n",
        "9.Harrison, O. (2019). Machine Learning Basics with the K-Nearest Neighbors Algorithm. [online] Medium. Available at: https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761 [Accessed 24 Aug. 2019]."
      ]
    }
  ]
}